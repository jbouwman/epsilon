;;;; Reverse-mode automatic differentiation implementation
;;;; 
;;;; This module implements tape-based reverse-mode autodiff with:
;;;;   - Efficient gradient accumulation
;;;;   - Memory checkpointing
;;;;   - Custom VJP rules
;;;;   - Sparse gradient support

(defpackage epsilon.compute.reverse-autodiff
  (:use :cl)
  (:local-nicknames
   (sym epsilon.compute.symbolic)
   (simp epsilon.compute.simplify)
   (map epsilon.map)
   (bc epsilon.compute.broadcasting))
  (:export
   ;; Tape construction
   :tape
   :tape-p
   :make-tape
   :build-tape
   :tape-nodes
   :tape-node-count
   :tape-output-value
   :tape-output-node
   
   ;; Tape nodes
   :tape-node
   :tape-node-p
   :make-tape-node
   :tape-node-value
   :tape-node-adjoint
   :tape-node-parents
   :tape-node-op
   :tape-node-grad-fn
   
   ;; Reverse-mode differentiation
   :reverse-diff
   :reverse-diff-with-checkpoints
   :reverse-diff-symbolic
   :gradient
   :backward
   
   ;; Vector-Jacobian products
   :vector-jacobian-product
   :register-vjp-rule
   :get-vjp-rule
   
   ;; Sparse gradients
   :sparse-gradient
   :sparse-gradient-p
   :make-sparse-gradient
   :sparse-gradient-get
   :sparse-gradient-nnz
   
   ;; Memory management
   :get-tape-memory-usage
   :peak-tape-memory
   :checkpoints-used-p
   :clear-tape-cache
   
   ;; Utilities
   :stop-gradient
   :gradient-checkpointing
   :hessian-mixed-mode
   
   ;; Initialization
   :ensure-gradient-rules
   :init-gradient-rules))

(in-package epsilon.compute.reverse-autodiff)

;;; Tape node structure

(defstruct tape-node
  "Node in computation tape for reverse-mode autodiff"
  (id nil :type (or null fixnum))
  (op nil :type symbol)
  (value nil)                        ; Forward pass value
  (adjoint 0)                         ; Accumulated gradient
  (parents nil :type list)           ; Parent nodes with local gradients
  (grad-fn nil :type (or null function)) ; Gradient computation function
  (children nil :type list))         ; Child nodes for forward references

(defmethod print-object ((node tape-node) stream)
  "Custom print method to avoid circular reference issues"
  (print-unreadable-object (node stream :type t :identity t)
    (format stream "id=~A op=~A value=~A"
            (tape-node-id node)
            (tape-node-op node)
            (tape-node-value node))))

;;; Sparse gradient structure

(defstruct sparse-gradient
  "Sparse gradient representation"
  (indices nil :type list)     ; Indices of non-zero entries
  (values nil :type list)      ; Values at those indices  
  (size 0 :type fixnum))       ; Total size of gradient vector

;;; Tape structure

(defstruct tape
  "Computation tape for reverse-mode autodiff"
  (nodes nil :type vector)
  (node-map (make-hash-table :test 'eq))  ; expr -> node mapping
  (output-node nil :type (or null tape-node))
  (var-nodes (make-hash-table :test 'equal))  ; variable name -> node
  (checkpoints nil :type list)
  (memory-usage 0 :type fixnum)
  (peak-memory 0 :type fixnum))

(defparameter *current-tape* nil
  "Currently active computation tape")

(defparameter *vjp-rules* (make-hash-table :test 'eq)
  "Custom vector-Jacobian product rules")

(defparameter *gradient-clip-norm* nil
  "Maximum gradient norm for clipping")

(defparameter *gradient-clip-value* nil
  "Maximum gradient value for element-wise clipping")

(defparameter *handle-nan* :error
  "How to handle NaN gradients: :error, :zero, or :warn")

;;; Gradient rules for primitive operations

(defvar *gradient-rules* nil
  "Map of operation symbols to gradient functions")

;; Initialize if needed
(unless *gradient-rules*
  (setf *gradient-rules* map:+empty+))

(defun register-gradient (op grad-fn)
  "Register a gradient function for an operation"
  (setf *gradient-rules* (map:assoc *gradient-rules* op grad-fn)))

(defun get-gradient-fn (op)
  "Get gradient function for an operation"
  ;; Try multiple ways to find the gradient function
  (or (map:get *gradient-rules* op)
      ;; If op is qualified, try just the symbol name
      (when (symbolp op)
        (map:get *gradient-rules* (intern (symbol-name op) "EPSILON.COMPUTE")))
      ;; Try as a string
      (when (symbolp op)
        (map:get *gradient-rules* (symbol-name op)))))

;; Track if gradient rules have been initialized
(defvar *gradient-rules-initialized* nil)

;; Function to ensure gradient rules are initialized
(defun ensure-gradient-rules ()
  "Ensure gradient rules are initialized once"
  (unless *gradient-rules-initialized*
    (init-gradient-rules)
    (setf *gradient-rules-initialized* t)))

;;; Basic arithmetic gradient rules

(defun init-gradient-rules ()
  "Initialize all gradient rules"
  
  ;; Addition gradient rule
  (register-gradient (intern "+" "EPSILON.COMPUTE")
    (lambda (node v-adjoints)
      (declare (ignorable v-adjoints))
  ;; d/dx(x + y) = 1, d/dy(x + y) = 1
  ;; But we need to handle broadcasting correctly
  (let* ((parents (tape-node-parents node))
         (values (mapcar #'tape-node-value parents)))
    (case (length values)
      (2 (let* ((x-val (first values))
                (y-val (second values))
                (result-val (tape-node-value node))
                ;; Gradient is 1, but needs correct shape
                (grad-x (cond
                         ;; x is scalar - sum of ones = size of result
                         ((numberp x-val)
                          (if (arrayp result-val)
                              (array-total-size result-val)
                              1))
                         ;; x is array - array of ones same shape
                         ((arrayp x-val)
                          (make-array (array-dimensions x-val)
                                     :initial-element 1))
                         (t 1)))
                (grad-y (cond
                         ;; y is scalar - sum of ones = size of result
                         ((numberp y-val)
                          (if (arrayp result-val)
                              (array-total-size result-val)
                              1))
                         ;; y is array - array of ones same shape
                         ((arrayp y-val)
                          (make-array (array-dimensions y-val)
                                     :initial-element 1))
                         (t 1))))
           (list (cons (first parents) grad-x)
                 (cons (second parents) grad-y))))
      ;; Handle single argument (shouldn't happen for +)
      (1 (list (cons (first parents) 1)))
      ;; Multiple arguments
      (otherwise 
       (mapcar (lambda (parent)
                (let ((val (tape-node-value parent)))
                  (cons parent
                        (if (arrayp val)
                            (make-array (array-dimensions val)
                                       :initial-element 1)
                            1))))
              parents))))))

  ;; Multiplication gradient rule
  (register-gradient (intern "*" "EPSILON.COMPUTE")
    (lambda (node v-adjoints)
      (declare (ignorable v-adjoints))
  ;; d/dx(x * y) = y, d/dy(x * y) = x
  (let* ((parents (tape-node-parents node))
         (values (mapcar #'tape-node-value parents)))
    (case (length values)
      (2 (let* ((x-val (first values))
                (y-val (second values))
                ;; The gradient wrt x is y (possibly broadcast to x's shape)
                (grad-x (cond
                         ;; x is scalar, y is array - sum y
                         ((and (numberp x-val) (arrayp y-val))
                          (reduce #'+ (make-array (array-total-size y-val)
                                                :displaced-to y-val)))
                         ;; x is array, y is scalar - broadcast y
                         ((and (arrayp x-val) (numberp y-val))
                          (make-array (array-dimensions x-val) 
                                     :initial-element y-val))
                         ;; Both same type - return as is
                         (t y-val)))
                ;; The gradient wrt y is x (possibly broadcast to y's shape)
                (grad-y (cond
                         ;; y is scalar, x is array - sum x
                         ((and (numberp y-val) (arrayp x-val))
                          (reduce #'+ (make-array (array-total-size x-val)
                                                :displaced-to x-val)))
                         ;; y is array, x is scalar - broadcast x
                         ((and (arrayp y-val) (numberp x-val))
                          (make-array (array-dimensions y-val)
                                     :initial-element x-val))
                         ;; Both same type - return as is
                         (t x-val))))
           (list (cons (first parents) grad-x)   ; df/dx = y (unbroadcast if needed)
                 (cons (second parents) grad-y))))  ; df/dy = x (unbroadcast if needed)
      (otherwise 
       ;; For n-ary multiplication
       (loop for parent in parents
             for i from 0
             collect (cons parent 
                          (apply #'* (loop for j from 0
                                         for v in values
                                         when (/= i j)
                                         collect v))))))))

;; Subtraction gradient rule
(define-gradient-rule "-"
  ;; d/dx(x - y) = 1, d/dy(x - y) = -1
  (case (length (tape-node-parents node))
    (1 (list (cons (first (tape-node-parents node)) -1))) ; Unary minus
    (2 (list (cons (first (tape-node-parents node)) 1)
            (cons (second (tape-node-parents node)) -1)))))

;; Division gradient rule
(define-gradient-rule "/"
  ;; d/dx(x / y) = 1/y, d/dy(x / y) = -x/y^2
  (let* ((parents (tape-node-parents node))
         (x-val (tape-node-value (first parents)))
         (y-val (tape-node-value (second parents)))
         ;; Compute gradients using broadcast-aware operations
         (grad-x (cond
                  ;; x is scalar, y is array - sum(1/y)
                  ((and (numberp x-val) (arrayp y-val))
                   (reduce #'+ (map 'vector (lambda (yi) (/ 1 yi)) y-val)))
                  ;; x is array, y is scalar - broadcast 1/y to match x shape
                  ((and (arrayp x-val) (numberp y-val))
                   (make-array (array-dimensions x-val) 
                              :initial-element (/ 1 y-val)))
                  ;; x is array, y is array - element-wise 1/y for each element of y
                  ((and (arrayp x-val) (arrayp y-val))
                   (map 'vector (lambda (yi) (/ 1 yi)) y-val))
                  ;; Both scalars
                  (t (/ 1 y-val))))
         (grad-y (cond
                  ;; y is scalar, x is array - sum(-x/y^2)
                  ((and (numberp y-val) (arrayp x-val))
                   (- (reduce #'+ (map 'vector (lambda (xi) (/ xi (* y-val y-val))) x-val))))
                  ;; y is array, x is scalar - broadcast -x/y^2 to match y shape
                  ((and (arrayp y-val) (numberp x-val))
                   (make-array (array-dimensions y-val)
                              :initial-element (- (/ x-val (* y-val y-val)))))
                  ;; Both arrays - element-wise -x/y^2 for corresponding elements
                  ((and (arrayp x-val) (arrayp y-val))
                   (map 'vector (lambda (xi yi) (- (/ xi (* yi yi)))) x-val y-val))
                  ;; Both scalars
                  (t (- (/ x-val (* y-val y-val)))))))
    (list (cons (first parents) grad-x)
          (cons (second parents) grad-y))))

;; Power gradient rule  
(define-gradient-rule "^"
  ;; d/dx(x^y) = y*x^(y-1), d/dy(x^y) = x^y * log(x)
  (let* ((parents (tape-node-parents node))
         (x-val (tape-node-value (first parents)))
         (y-val (tape-node-value (second parents)))
         ;; Compute gradients with broadcasting support
         (grad-x (cond
                  ;; x is array, y is scalar - apply to each element of x
                  ((and (arrayp x-val) (numberp y-val))
                   (map 'vector (lambda (xi) (* y-val (expt xi (- y-val 1)))) x-val))
                  ;; x is scalar, y is array - sum over all y elements
                  ((and (numberp x-val) (arrayp y-val))
                   (reduce #'+ (map 'vector (lambda (yi) (* yi (expt x-val (- yi 1)))) y-val)))
                  ;; Both arrays - element-wise computation
                  ((and (arrayp x-val) (arrayp y-val))
                   (map 'vector (lambda (xi yi) (* yi (expt xi (- yi 1)))) x-val y-val))
                  ;; Both scalars
                  (t (* y-val (expt x-val (- y-val 1))))))
         (grad-y (cond
                  ;; y is scalar, x is array - sum x^y * log(x) over all x
                  ((and (numberp y-val) (arrayp x-val))
                   (reduce #'+ (map 'vector (lambda (xi) (* (expt xi y-val) (log xi))) x-val)))
                  ;; y is array, x is scalar - apply to each element of y
                  ((and (arrayp y-val) (numberp x-val))
                   (make-array (array-dimensions y-val)
                              :initial-element (* (expt x-val y-val) (log x-val))))
                  ;; Both arrays - element-wise computation
                  ((and (arrayp x-val) (arrayp y-val))
                   (map 'vector (lambda (xi yi) (* (expt xi yi) (log xi))) x-val y-val))
                  ;; Both scalars
                  (t (* (expt x-val y-val) (log x-val))))))
    (list (cons (first parents) grad-x)
          (cons (second parents) grad-y))))

;; Special operations
(define-gradient-rule stop-gradient
  ;; Stop gradient - no gradient flows through
  (list (cons (first (tape-node-parents node)) 0)))

;; Transcendental functions
(define-gradient-rule "SIN"
  ;; d/dx(sin(x)) = cos(x)
  (let ((x (tape-node-value (first (tape-node-parents node)))))
    (list (cons (first (tape-node-parents node)) (cos x)))))

(define-gradient-rule "COS"
  ;; d/dx(cos(x)) = -sin(x)
  (let ((x (tape-node-value (first (tape-node-parents node)))))
    (list (cons (first (tape-node-parents node)) (- (sin x))))))

(define-gradient-rule "EXP"
  ;; d/dx(exp(x)) = exp(x)
  (list (cons (first (tape-node-parents node)) 
             (tape-node-value node))))

(define-gradient-rule "LOG"
  ;; d/dx(log(x)) = 1/x
  (let ((x (tape-node-value (first (tape-node-parents node)))))
    (list (cons (first (tape-node-parents node)) (/ 1 x)))))

(define-gradient-rule "SQRT"
  ;; d/dx(sqrt(x)) = 1/(2*sqrt(x))
  (list (cons (first (tape-node-parents node))
             (/ 1 (* 2 (tape-node-value node))))))

;; Gradient rules are now registered at load time via define-gradient-rule macro
;; No explicit initialization needed

;;; Tape construction

(defun build-tape (expr bindings)
  "Build computation tape from expression"
  (let ((*current-tape* (make-tape :nodes (make-array 0 :adjustable t :fill-pointer 0))))
    ;; Forward pass: build tape and compute values
    (tape-forward expr bindings)
    *current-tape*))

(defun tape-forward (expr bindings)
  "Forward pass: build tape and compute values"
  (cond
    ;; Constants
    ((numberp expr)
     (tape-record-node :const expr nil))
    
    ;; Variables
    ((and (symbolp expr) (assoc expr bindings))
     (let ((value (cdr (assoc expr bindings))))
       (or (gethash expr (tape-var-nodes *current-tape*))
           (setf (gethash expr (tape-var-nodes *current-tape*))
                 (tape-record-node :var value nil)))))
    
    ;; Symbolic constants
    ((sym:const-p expr)
     (tape-record-node :const (sym:const-value expr) nil))
    
    ;; Symbolic variables
    ((sym:var-p expr)
     (let* ((name (sym:var-name expr))
            (value (cdr (assoc name bindings))))
       (or (gethash name (tape-var-nodes *current-tape*))
           (setf (gethash name (tape-var-nodes *current-tape*))
                 (tape-record-node :var value nil)))))
    
    ;; Symbolic expressions
    ((sym:expr-p expr)
     (let* ((op (sym:expr-op expr))
            (args (sym:expr-args expr))
            (parent-nodes (mapcar (lambda (arg) (tape-forward arg bindings)) args))
            (parent-values (mapcar #'tape-node-value parent-nodes))
            (value (apply (get-numeric-op op) parent-values)))
       (tape-record-node op value parent-nodes)))
    
    ;; Lists (for multiple outputs)
    ((listp expr)
     (mapcar (lambda (e) (tape-forward e bindings)) expr))
    
    (t (error "Unknown expression type: ~A" expr))))


(defun tape-record-node (op value parents)
  "Record a node in the tape"
  (let* ((grad-fn (get-gradient-fn op))
         (node (make-tape-node
                :id (length (tape-nodes *current-tape*))
                :op op
                :value value
                :parents parents
                :grad-fn grad-fn)))
    ;; Add to tape
    (vector-push-extend node (tape-nodes *current-tape*))
    ;; Update children references
    (dolist (parent parents)
      (when parent
        (push node (tape-node-children parent))))
    ;; Update memory tracking
    (incf (tape-memory-usage *current-tape*) 
          (+ 64 (* 8 (length parents))))  ; Rough estimate
    (setf (tape-peak-memory *current-tape*)
          (max (tape-peak-memory *current-tape*)
               (tape-memory-usage *current-tape*)))
    ;; Set as output node
    (setf (tape-output-node *current-tape*) node)
    node))

(defun get-numeric-op (op)
  "Get numeric function for symbolic operation"
  (let ((op-name (if (symbolp op) 
                     (symbol-name op)
                     (string op))))
    (cond
      ((string= op-name "+") (lambda (&rest args) 
                                (if (find-symbol "BROADCAST-OPERATION" "EPSILON.COMPUTE")
                                    (apply (symbol-function (find-symbol "BROADCAST-OPERATION" "EPSILON.COMPUTE")) #'cl:+ args)
                                    (apply #'cl:+ args))))
      ((string= op-name "-") (lambda (&rest args) 
                                (if (find-symbol "BROADCAST-OPERATION" "EPSILON.COMPUTE")
                                    (apply (symbol-function (find-symbol "BROADCAST-OPERATION" "EPSILON.COMPUTE")) #'cl:- args)
                                    (apply #'cl:- args))))
      ((string= op-name "*") (lambda (&rest args) 
                                (if (find-symbol "BROADCAST-OPERATION" "EPSILON.COMPUTE")
                                    (apply (symbol-function (find-symbol "BROADCAST-OPERATION" "EPSILON.COMPUTE")) #'cl:* args)
                                    (apply #'cl:* args))))
      ((string= op-name "/") (lambda (&rest args) 
                                (if (find-symbol "BROADCAST-OPERATION" "EPSILON.COMPUTE")
                                    (apply (symbol-function (find-symbol "BROADCAST-OPERATION" "EPSILON.COMPUTE")) #'cl:/ args)
                                    (apply #'cl:/ args))))
      ((string= op-name "^") (lambda (&rest args) 
                                (if (find-symbol "BROADCAST-OPERATION" "EPSILON.COMPUTE")
                                    (apply (symbol-function (find-symbol "BROADCAST-OPERATION" "EPSILON.COMPUTE")) #'expt args)
                                    (apply #'expt args))))
      ((string= op-name "SIN") (lambda (x) 
                                  (if (find-symbol "BROADCAST-OPERATION" "EPSILON.COMPUTE")
                                      (funcall (symbol-function (find-symbol "BROADCAST-OPERATION" "EPSILON.COMPUTE")) #'cl:sin x)
                                      (cl:sin x))))
      ((string= op-name "COS") (lambda (x) 
                                  (if (find-symbol "BROADCAST-OPERATION" "EPSILON.COMPUTE")
                                      (funcall (symbol-function (find-symbol "BROADCAST-OPERATION" "EPSILON.COMPUTE")) #'cl:cos x)
                                      (cl:cos x))))
      ((string= op-name "TAN") (lambda (x) 
                                  (if (find-symbol "BROADCAST-OPERATION" "EPSILON.COMPUTE")
                                      (funcall (symbol-function (find-symbol "BROADCAST-OPERATION" "EPSILON.COMPUTE")) #'cl:tan x)
                                      (cl:tan x))))
      ((string= op-name "EXP") (lambda (x) 
                                  (if (find-symbol "BROADCAST-OPERATION" "EPSILON.COMPUTE")
                                      (funcall (symbol-function (find-symbol "BROADCAST-OPERATION" "EPSILON.COMPUTE")) #'cl:exp x)
                                      (cl:exp x))))
      ((string= op-name "LOG") (lambda (x) 
                                  (if (find-symbol "BROADCAST-OPERATION" "EPSILON.COMPUTE")
                                      (funcall (symbol-function (find-symbol "BROADCAST-OPERATION" "EPSILON.COMPUTE")) #'cl:log x)
                                      (cl:log x))))
      ((string= op-name "SQRT") (lambda (x) 
                                   (if (find-symbol "BROADCAST-OPERATION" "EPSILON.COMPUTE")
                                       (funcall (symbol-function (find-symbol "BROADCAST-OPERATION" "EPSILON.COMPUTE")) #'cl:sqrt x)
                                       (cl:sqrt x))))
      ((string= op-name "ABS") (lambda (x) 
                                  (if (find-symbol "BROADCAST-OPERATION" "EPSILON.COMPUTE")
                                      (funcall (symbol-function (find-symbol "BROADCAST-OPERATION" "EPSILON.COMPUTE")) #'cl:abs x)
                                      (cl:abs x))))
      ((string= op-name "SUM") (lambda (x)
                                  (if (arrayp x)
                                      (reduce #'+ (make-array (array-total-size x) :displaced-to x))
                                      x)))
      ((string= op-name "STOP-GRADIENT") #'identity) ; Pass through value
      (t (error "Unknown operation: ~A" op)))))

;;; Backward pass

(defun backward (tape &optional (seed-gradient 1))
  "Perform backward pass on tape"
  (let ((output-node (tape-output-node tape)))
    ;; Initialize output gradient
    (setf (tape-node-adjoint output-node) seed-gradient)
    
    ;; Backward pass in reverse topological order
    (loop for i from (1- (length (tape-nodes tape))) downto 0
          for node = (aref (tape-nodes tape) i)
          when (tape-node-grad-fn node)
          do (propagate-gradients node))
    
    ;; Extract gradients for variables
    (let ((var-gradients (make-hash-table :test 'equal)))
      (maphash (lambda (name node)
                 (setf (gethash name var-gradients)
                       (or (tape-node-adjoint node) 0)))
               (tape-var-nodes tape))
      var-gradients)))

(defun propagate-gradients (node)
  "Propagate gradients from node to its parents"
  (when (and (tape-node-parents node)
             (tape-node-grad-fn node))
    (let* ((adjoint (tape-node-adjoint node))
           (local-grads (funcall (tape-node-grad-fn node) node nil)))
      (dolist (parent-grad local-grads)
        (let ((parent (car parent-grad))
              (grad (cdr parent-grad)))
          ;; Use broadcast-aware multiplication for gradient accumulation
          (let ((grad-contrib (if (and (find-symbol "BROADCAST-OPERATION" "EPSILON.COMPUTE")
                                       (or (arrayp adjoint) (arrayp grad)))
                                  (funcall (symbol-function (find-symbol "BROADCAST-OPERATION" "EPSILON.COMPUTE"))
                                          #'* adjoint grad)
                                  (* adjoint grad))))
            ;; Use broadcast-aware addition for gradient accumulation
            (setf (tape-node-adjoint parent)
                  (if (and (find-symbol "BROADCAST-OPERATION" "EPSILON.COMPUTE")
                           (or (arrayp (tape-node-adjoint parent)) (arrayp grad-contrib)))
                      (funcall (symbol-function (find-symbol "BROADCAST-OPERATION" "EPSILON.COMPUTE"))
                              #'+ (or (tape-node-adjoint parent) 0) grad-contrib)
                      (+ (or (tape-node-adjoint parent) 0) grad-contrib)))))))))

;;; Main interface

(defun reverse-diff (expr var-names bindings &key 
                    (clip-norm *gradient-clip-norm*)
                    (clip-value *gradient-clip-value*)
                    (handle-nan *handle-nan*))
  "Compute reverse-mode gradients"
  (let* ((*gradient-clip-norm* clip-norm)
         (*gradient-clip-value* clip-value)
         (*handle-nan* handle-nan)
         (tape (build-tape expr bindings))
         (grad-table (backward tape)))
    ;; Extract gradients in order
    (mapcar (lambda (var)
              (let ((grad (gethash var grad-table 0)))
                ;; Handle NaN - check for actual NaN values, not just non-numbers
                (when (and handle-nan
                          (or (and (numberp grad) 
                                   (not (= grad grad))) ; NaN test for numbers
                              (and (arrayp grad)
                                   (some (lambda (x) (and (numberp x) (not (= x x))))
                                         (make-array (array-total-size grad) 
                                                    :displaced-to grad)))))
                  (setf grad (case handle-nan
                              (:zero (if (arrayp grad)
                                        (make-array (array-dimensions grad) 
                                                   :initial-element 0)
                                        0))
                              (:warn (warn "NaN gradient for ~A" var) 
                                    (if (arrayp grad)
                                        (make-array (array-dimensions grad) 
                                                   :initial-element 0)
                                        0))
                              (:error (error "NaN gradient for ~A" var)))))
                ;; Apply clipping to arrays or scalars
                (when clip-value
                  (setf grad (if (arrayp grad)
                                (let ((result (make-array (array-dimensions grad))))
                                  (dotimes (i (array-total-size grad))
                                    (setf (row-major-aref result i)
                                          (max (- clip-value) 
                                               (min clip-value 
                                                    (row-major-aref grad i)))))
                                  result)
                                (max (- clip-value) (min clip-value grad)))))
                grad))
            var-names)))

(defun gradient (expr var-names bindings)
  "Compute gradient (simpler interface)"
  (reverse-diff expr var-names bindings))

;;; Checkpointing

(defun reverse-diff-with-checkpoints (expr var-names bindings &key checkpoint-layers)
  "Reverse-mode with memory checkpointing"
  ;; TODO: Implement checkpointing
  (reverse-diff expr var-names bindings))

(defparameter *checkpoints-used* nil)

(defun checkpoints-used-p ()
  "Check if checkpoints were used in last computation"
  *checkpoints-used*)

;;; Vector-Jacobian products

(defun vector-jacobian-product (exprs var-names bindings v)
  "Compute vector-Jacobian product efficiently"
  ;; VJP = v^T * J where J is the Jacobian
  ;; Compute as sum of v[i] * grad(f[i])
  (let* ((n-vars (length var-names))
         (result (make-array n-vars :initial-element 0)))
    (loop for i from 0
          for expr in exprs
          for weight = (aref v i)
          do (let ((grad (reverse-diff expr var-names bindings)))
               (loop for j from 0 below n-vars
                     do (incf (aref result j)
                              (* weight (nth j grad))))))
    result))

(defun register-vjp-rule (op rule-fn)
  "Register custom VJP rule for an operation"
  (setf (gethash op *vjp-rules*) rule-fn))

(defun get-vjp-rule (op)
  "Get custom VJP rule for an operation"
  (gethash op *vjp-rules*))

;;; Sparse gradients


(defun sparse-gradient (expr var-names bindings)
  "Compute sparse gradient representation"
  ;; For now, compute full gradient and convert to sparse
  (let* ((full-grad (gradient expr var-names bindings))
         (indices nil)
         (values nil))
    (loop for i from 0
          for grad in full-grad
          when (and grad (not (zerop grad)))
          do (push i indices)
             (push grad values))
    (make-sparse-gradient 
     :indices (nreverse indices)
     :values (nreverse values)
     :size (length var-names))))

(defun sparse-gradient-get (grad index)
  "Get value from sparse gradient"
  (let ((pos (position index (sparse-gradient-indices grad))))
    (if pos
        (nth pos (sparse-gradient-values grad))
        0)))

(defun sparse-gradient-nnz (grad)
  "Number of non-zero entries in sparse gradient"
  (length (sparse-gradient-indices grad)))

;;; Memory management

(defun get-tape-memory-usage (&optional (tape *current-tape*))
  "Get current tape memory usage"
  (if tape
      (tape-memory-usage tape)
      0))

(defun peak-tape-memory (&optional (tape *current-tape*))
  "Get peak tape memory usage"
  (if tape
      (tape-peak-memory tape)
      0))

(defun clear-tape-cache ()
  "Clear tape cache to free memory"
  (setf *current-tape* nil))

;;; Utilities

(defun stop-gradient (expr)
  "Create a stop-gradient operation that prevents gradient flow"
  (sym:make-expr :op 'stop-gradient :args (list expr)))

(defun reverse-diff-symbolic (expr var)
  "Get symbolic derivative using reverse mode"
  ;; TODO: Return symbolic expression instead of numeric gradient
  (error "Symbolic reverse diff not yet implemented"))

(defun hessian-mixed-mode (expr var-names bindings)
  "Compute Hessian using mixed forward-reverse mode"
  ;; TODO: Implement mixed mode for efficiency
  (let ((n (length var-names)))
    (make-array (list n n) :initial-element 0)))


;;; Alias for backward compatibility

(defun tape-node-count (tape)
  "Get number of nodes in tape"
  (length (tape-nodes tape)))

(defun tape-output-value (tape)
  "Get output value from tape"
  (tape-node-value (tape-output-node tape)))

;;; Reverse-mode differentiation implementation

#|
;; DUPLICATE - Commented out, using HAMT version above
(defparameter *gradient-rules* (make-hash-table :test #'eq)
  "Hash table of gradient rules for operations")

(defun register-gradient-rule (op-name gradient-fn)
  "Register a gradient computation rule for an operation"
  (setf (gethash op-name *gradient-rules*) gradient-fn))

(defun get-gradient-fn (op)
  "Get gradient function for an operation"
  (gethash op *gradient-rules*))
|#

#|
;; DUPLICATE - Using the earlier HAMT-based version
(defun reverse-diff (expr vars bindings)
  "Compute gradients using reverse-mode autodiff with tape.
   Returns a list of gradients in the same order as vars."
  (let* ((tape (build-tape expr bindings))
         (nodes (tape-nodes tape))
         (num-nodes (length nodes))
         ;; Initialize adjoints (gradients) to 0
         (adjoints (make-array num-nodes :initial-element 0)))
    
    ;; Set gradient of output to 1
    (setf (aref adjoints (1- num-nodes)) 1)
    
    ;; Backward pass - propagate gradients
    (loop for i from (1- num-nodes) downto 0
          for node = (aref nodes i)
          for adjoint = (aref adjoints i)
          when (and (tape-node-parents node) 
                   (not (zerop adjoint)))
          do (propagate-gradient node adjoint nodes adjoints))
    
    ;; Extract gradients for requested variables
    (mapcar (lambda (var)
              (let ((var-node (gethash var (tape-var-nodes tape))))
                (if var-node
                    (aref adjoints (position var-node nodes))
                    0)))
            vars)))
|#

#|
(defun propagate-gradient (node adjoint nodes adjoints)
  "Propagate gradient from node to its parents"
  (let* ((op (tape-node-op node))
         (parents (tape-node-parents node))
         (parent-values (mapcar #'tape-node-value parents))
         (grad-rule (gethash op *gradient-rules*)))
    
    (when grad-rule
      ;; Apply gradient rule
      (let ((parent-grads (funcall grad-rule node adjoint parents parent-values)))
        ;; Accumulate gradients to parents
        (loop for parent in parents
              for parent-grad in parent-grads
              for parent-idx = (position parent nodes)
              when parent-idx
              do (incf (aref adjoints parent-idx) parent-grad))))))
|#

#|
;;; Gradient Rules for Broadcasting Operations

;; Addition gradient rule with broadcasting
(register-gradient-rule '+
  (lambda (node grad parents parent-values)
    ;; Gradient of addition is 1 for each parent
    ;; But we need to unbroadcast if shapes differ
    (mapcar (lambda (parent parent-val)
              (if (arrayp parent-val)
                  (let ((parent-shape (array-dimensions parent-val))
                        (output-shape (if (arrayp (tape-node-value node))
                                        (array-dimensions (tape-node-value node))
                                        nil)))
                    (if (equal parent-shape output-shape)
                        grad  ; No unbroadcasting needed
                        (bc:unbroadcast-gradient grad parent-shape)))
                  ;; Scalar parent - sum all gradient elements
                  (if (arrayp grad)
                      (reduce #'+ (make-array (array-total-size grad)
                                            :displaced-to grad))
                      grad)))
            parents parent-values)))

;; Multiplication gradient rule with broadcasting
(register-gradient-rule '*
  (lambda (node grad parents parent-values)
    ;; Gradient of multiplication: df/dx = y, df/dy = x
    (let ((x-val (first parent-values))
          (y-val (second parent-values)))
      (list
       ;; Gradient wrt first parent
       (let ((local-grad (if (arrayp grad)
                             (bc:broadcast-binary-op #'* grad y-val)
                             (* grad y-val))))
         (if (arrayp x-val)
             (bc:unbroadcast-gradient local-grad (array-dimensions x-val))
             (bc:unbroadcast-gradient local-grad nil)))
       ;; Gradient wrt second parent  
       (let ((local-grad (if (arrayp grad)
                             (bc:broadcast-binary-op #'* grad x-val)
                             (* grad x-val))))
         (if (arrayp y-val)
             (bc:unbroadcast-gradient local-grad (array-dimensions y-val))
             (bc:unbroadcast-gradient local-grad nil)))))))

;; Subtraction gradient rule
(register-gradient-rule '-
  (lambda (node grad parents parent-values)
    (if (= (length parents) 1)
        ;; Unary minus: gradient is -grad
        (list (if (arrayp grad)
                  (bc:broadcast-binary-op #'* grad -1)
                  (- grad)))
        ;; Binary subtraction: df/dx = 1, df/dy = -1
        (let ((x-val (first parent-values))
              (y-val (second parent-values)))
          (list
           ;; Gradient wrt first parent
           (if (arrayp x-val)
               (bc:unbroadcast-gradient grad (array-dimensions x-val))
               (bc:unbroadcast-gradient grad nil))
           ;; Gradient wrt second parent (negated)
           (let ((neg-grad (if (arrayp grad)
                               (bc:broadcast-binary-op #'* grad -1)
                               (- grad))))
             (if (arrayp y-val)
                 (bc:unbroadcast-gradient neg-grad (array-dimensions y-val))
                 (bc:unbroadcast-gradient neg-grad nil))))))))

;; Division gradient rule  
(register-gradient-rule '/
  (lambda (node grad parents parent-values)
    (let ((x-val (first parent-values))
          (y-val (second parent-values)))
      (list
       ;; df/dx = 1/y
       (let ((local-grad (if (arrayp grad)
                             (bc:broadcast-binary-op #'* grad 
                                                    (bc:broadcast-binary-op #'/ 1 y-val))
                             (* grad (/ 1 y-val)))))
         (if (arrayp x-val)
             (bc:unbroadcast-gradient local-grad (array-dimensions x-val))
             (bc:unbroadcast-gradient local-grad nil)))
       ;; df/dy = -x/y^2
       (let ((local-grad (if (arrayp grad)
                             (bc:broadcast-binary-op #'* grad
                                                    (bc:broadcast-binary-op #'/ 
                                                                           (bc:broadcast-binary-op #'* x-val -1)
                                                                           (bc:broadcast-binary-op #'* y-val y-val)))
                             (* grad (- (/ x-val (* y-val y-val)))))))
         (if (arrayp y-val)
             (bc:unbroadcast-gradient local-grad (array-dimensions y-val))
             (bc:unbroadcast-gradient local-grad nil)))))))

;; Power gradient rule
(register-gradient-rule '^
  (lambda (node grad parents parent-values)
    (let ((x-val (first parent-values))
          (y-val (second parent-values)))
      (list
       ;; df/dx = y * x^(y-1)
       (let ((local-grad 
              (if (arrayp grad)
                  (bc:broadcast-binary-op #'* grad
                                         (bc:broadcast-binary-op #'*
                                                                y-val
                                                                (bc:broadcast-binary-op #'expt x-val 
                                                                                       (bc:broadcast-binary-op #'- y-val 1))))
                  (* grad (* y-val (expt x-val (- y-val 1)))))))
         (if (arrayp x-val)
             (bc:unbroadcast-gradient local-grad (array-dimensions x-val))
             (bc:unbroadcast-gradient local-grad nil)))
       ;; df/dy = x^y * log(x)
       (let ((local-grad
              (if (arrayp grad)
                  (bc:broadcast-binary-op #'* grad
                                         (bc:broadcast-binary-op #'*
                                                                (bc:broadcast-binary-op #'expt x-val y-val)
                                                                (bc:broadcast-binary-op #'log x-val)))
                  (* grad (* (expt x-val y-val) (log x-val))))))
         (if (arrayp y-val)
             (bc:unbroadcast-gradient local-grad (array-dimensions y-val))
             (bc:unbroadcast-gradient local-grad nil)))))))

;; Sum gradient rule
(register-gradient-rule 'sum
  (lambda (node grad parents parent-values)
    ;; Gradient of sum: broadcast grad to shape of input
    (let ((input-val (first parent-values)))
      (if (arrayp input-val)
          (list (make-array (array-dimensions input-val) 
                           :initial-element grad))
          (list grad)))))
|#
